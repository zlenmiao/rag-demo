# å¤šåª’ä½“RAGç³»ç»Ÿé›†æˆæŒ‡å—

## ğŸ“‹ é›†æˆæ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šå®‰è£…æ–°å¢ä¾èµ–

```bash
# å®‰è£…è¡¨æ ¼å¤„ç†ä¾èµ–
pip install pandas openpyxl

# å¯é€‰ï¼šæ›´é«˜çº§çš„å›¾è¡¨å¤„ç†
pip install matplotlib seaborn plotly

# å¯é€‰ï¼šPDFå¤„ç†æ”¯æŒ
pip install PyPDF2 pdfplumber

# å¯é€‰ï¼šWordæ–‡æ¡£æ”¯æŒ
pip install python-docx
```

### ç¬¬äºŒæ­¥ï¼šä¿®æ”¹ç°æœ‰çš„RAGç³»ç»Ÿ

#### 2.1 æ‰©å±•æ•°æ®æ¨¡å‹ (data_models.py)

```python
# åœ¨ç°æœ‰çš„ data_models.py æ–‡ä»¶æœ«å°¾æ·»åŠ 

@dataclass
class TableContent:
    """è¡¨æ ¼å†…å®¹æ•°æ®ç»“æ„"""
    headers: List[str]
    rows: List[List[str]]
    summary: str
    source_file: str
    metadata: Dict = field(default_factory=dict)

@dataclass
class ChartContent:
    """å›¾è¡¨å†…å®¹æ•°æ®ç»“æ„"""
    chart_type: str
    data_points: List[Dict]
    description: str
    trends: str
    source_file: str
    metadata: Dict = field(default_factory=dict)

@dataclass
class EnhancedDocument(Document):
    """æ‰©å±•çš„æ–‡æ¡£æ¨¡å‹"""
    content_type: str = 'text'
    tables: List[TableContent] = field(default_factory=list)
    charts: List[ChartContent] = field(default_factory=list)
    images_metadata: List[Dict] = field(default_factory=list)

    def to_legacy_document(self) -> Document:
        """ä¿æŒå‘å‰å…¼å®¹"""
        return Document(
            id=self.id,
            title=self.title,
            content=self.content,
            paragraphs=self.paragraphs,
            metadata=self.metadata,
            created_at=self.created_at
        )
```

#### 2.2 ä¿®æ”¹RAGç³»ç»Ÿä¸»ç±» (rag_system.py)

```python
# åœ¨æ–‡ä»¶é¡¶éƒ¨æ·»åŠ å¯¼å…¥
from multimodal_processor import MultiModalProcessor, EnhancedDocument

class AdvancedRAGSystem:
    def __init__(self):
        # ç°æœ‰ä»£ç ä¿æŒä¸å˜
        self.processor = DataProcessor()
        self.vector_store = IntelligentVectorStore()
        self.llm_client = LLMClient()
        self.conversation_manager = ConversationManager()
        self.image_processor = ImageProcessor()

        # æ–°å¢å¤šæ¨¡æ€å¤„ç†å™¨
        self.multimodal_processor = MultiModalProcessor()

        # åŠ è½½å­˜å‚¨
        self.vector_store.load_from_file()

        # æ€§èƒ½ç»Ÿè®¡ä¿æŒä¸å˜
        self.stats = {
            "total_queries": 0,
            "avg_response_time": 0,
            "avg_confidence": 0
        }

    def build_knowledge_base(self, data_dir: str, include_images: bool = True, include_tables: bool = True) -> Dict:
        """æ‰©å±•çš„çŸ¥è¯†åº“æ„å»ºæ–¹æ³•"""
        if not os.path.exists(data_dir):
            return {"success": False, "message": f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}"}

        # é‡ç½®å‘é‡å­˜å‚¨
        self.vector_store = IntelligentVectorStore()

        results = {
            "total_files": 0,
            "text_files": 0,
            "image_files": 0,
            "table_files": 0,
            "chart_files": 0,
            "errors": []
        }

        try:
            # ä½¿ç”¨å¤šæ¨¡æ€å¤„ç†å™¨æ‰¹é‡å¤„ç†
            documents = self.multimodal_processor.batch_process_directory(data_dir)

            for doc in documents:
                try:
                    # ç»Ÿè®¡æ–‡ä»¶ç±»å‹
                    results["total_files"] += 1
                    if doc.content_type == 'text':
                        results["text_files"] += 1
                    elif doc.content_type == 'image':
                        results["image_files"] += 1
                    elif doc.content_type == 'table':
                        results["table_files"] += 1
                    elif doc.content_type == 'chart':
                        results["chart_files"] += 1

                    # è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼å¹¶æ·»åŠ åˆ°å‘é‡å­˜å‚¨
                    legacy_doc = doc.to_legacy_document()
                    self.vector_store.add_document(legacy_doc)

                except Exception as e:
                    logger.error(f"å¤„ç†æ–‡æ¡£å¤±è´¥ {doc.title}: {e}")
                    results["errors"].append(f"{doc.title}: {str(e)}")

            # ä¿å­˜åˆ°æ–‡ä»¶
            self.vector_store.save_to_file()

            results["success"] = True
            results["message"] = f"æˆåŠŸæ„å»ºçŸ¥è¯†åº“ï¼Œå…±å¤„ç†{results['total_files']}ä¸ªæ–‡ä»¶"

            return results

        except Exception as e:
            logger.error(f"æ„å»ºçŸ¥è¯†åº“å¤±è´¥: {e}")
            return {"success": False, "message": f"æ„å»ºå¤±è´¥: {str(e)}"}
```

#### 2.3 æ‰©å±•Webç•Œé¢ (web_app.py)

```python
# åœ¨ç°æœ‰çš„ /build è·¯ç”±ä¸­æ·»åŠ å¤šåª’ä½“æ”¯æŒ

@app.route('/build', methods=['POST'])
def build_knowledge_base():
    try:
        data = request.get_json()
        data_dir = data.get('data_dir', 'test_data')
        include_images = data.get('include_images', True)
        include_tables = data.get('include_tables', True)  # æ–°å¢å‚æ•°

        # è°ƒç”¨æ‰©å±•çš„æ„å»ºæ–¹æ³•
        result = rag_system.build_knowledge_base(
            data_dir,
            include_images=include_images,
            include_tables=include_tables
        )

        return jsonify(result)

    except Exception as e:
        logger.error(f"æ„å»ºçŸ¥è¯†åº“APIé”™è¯¯: {e}")
        return jsonify({"success": False, "message": str(e)}), 500

# æ–°å¢å¤šåª’ä½“æ–‡ä»¶ä¸Šä¼ æ”¯æŒ
@app.route('/upload_multimodal', methods=['POST'])
def upload_multimodal_file():
    """ä¸Šä¼ å¤šåª’ä½“æ–‡ä»¶å¹¶å¤„ç†"""
    try:
        if 'file' not in request.files:
            return jsonify({"success": False, "message": "æ²¡æœ‰æ–‡ä»¶"}), 400

        file = request.files['file']
        if file.filename == '':
            return jsonify({"success": False, "message": "æ–‡ä»¶åä¸ºç©º"}), 400

        # ä¿å­˜æ–‡ä»¶
        filename = secure_filename(file.filename)
        upload_path = os.path.join('uploads', filename)
        os.makedirs('uploads', exist_ok=True)
        file.save(upload_path)

        # å¤„ç†æ–‡ä»¶
        doc = rag_system.multimodal_processor.process_file(upload_path)

        # æ·»åŠ åˆ°çŸ¥è¯†åº“
        legacy_doc = doc.to_legacy_document()
        rag_system.vector_store.add_document(legacy_doc)
        rag_system.vector_store.save_to_file()

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.remove(upload_path)

        return jsonify({
            "success": True,
            "message": f"æˆåŠŸå¤„ç†{doc.content_type}æ–‡ä»¶: {filename}",
            "content_type": doc.content_type,
            "content_length": len(doc.content)
        })

    except Exception as e:
        logger.error(f"ä¸Šä¼ å¤„ç†å¤±è´¥: {e}")
        return jsonify({"success": False, "message": str(e)}), 500
```

#### 2.4 æ›´æ–°å‰ç«¯ç•Œé¢ (templates/index.html)

```html
<!-- åœ¨ç°æœ‰çš„æ„å»ºçŸ¥è¯†åº“éƒ¨åˆ†æ·»åŠ å¤šåª’ä½“é€‰é¡¹ -->
<div class="build-section">
    <h3>ğŸ“š æ„å»ºçŸ¥è¯†åº“</h3>
    <div class="build-options">
        <label>
            <input type="checkbox" id="include_images" checked> åŒ…å«å›¾ç‰‡å¤„ç†
        </label>
        <label>
            <input type="checkbox" id="include_tables" checked> åŒ…å«è¡¨æ ¼å¤„ç†
        </label>
    </div>
    <input type="text" id="data-dir" placeholder="æ•°æ®ç›®å½•è·¯å¾„" value="test_data">
    <button onclick="buildKnowledgeBase()">ğŸ”„ æ„å»ºçŸ¥è¯†åº“</button>
    <div id="build-status"></div>
</div>

<!-- æ–°å¢å¤šåª’ä½“æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ -->
<div class="upload-section">
    <h3>ğŸ“ ä¸Šä¼ å¤šåª’ä½“æ–‡ä»¶</h3>
    <input type="file" id="multimodal-file" accept=".txt,.csv,.xlsx,.xls,.jpg,.jpeg,.png,.pdf">
    <button onclick="uploadMultimodalFile()">â¬†ï¸ ä¸Šä¼ å¹¶å¤„ç†</button>
    <div id="upload-status"></div>
</div>

<script>
// ä¿®æ”¹æ„å»ºçŸ¥è¯†åº“å‡½æ•°
async function buildKnowledgeBase() {
    const dataDir = document.getElementById('data-dir').value;
    const includeImages = document.getElementById('include_images').checked;
    const includeTables = document.getElementById('include_tables').checked;
    const statusDiv = document.getElementById('build-status');

    statusDiv.innerHTML = 'ğŸ”„ æ­£åœ¨æ„å»ºçŸ¥è¯†åº“...';

    try {
        const response = await fetch('/build', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({
                data_dir: dataDir,
                include_images: includeImages,
                include_tables: includeTables
            })
        });

        const result = await response.json();

        if (result.success) {
            statusDiv.innerHTML = `âœ… ${result.message}
                <br>ğŸ“Š ç»Ÿè®¡: æ–‡æœ¬${result.text_files || 0}ä¸ª, å›¾ç‰‡${result.image_files || 0}ä¸ª,
                è¡¨æ ¼${result.table_files || 0}ä¸ª, å›¾è¡¨${result.chart_files || 0}ä¸ª`;
        } else {
            statusDiv.innerHTML = `âŒ ${result.message}`;
        }
    } catch (error) {
        statusDiv.innerHTML = `âŒ æ„å»ºå¤±è´¥: ${error}`;
    }
}

// æ–°å¢æ–‡ä»¶ä¸Šä¼ å‡½æ•°
async function uploadMultimodalFile() {
    const fileInput = document.getElementById('multimodal-file');
    const statusDiv = document.getElementById('upload-status');

    if (!fileInput.files[0]) {
        statusDiv.innerHTML = 'âŒ è¯·é€‰æ‹©æ–‡ä»¶';
        return;
    }

    const formData = new FormData();
    formData.append('file', fileInput.files[0]);

    statusDiv.innerHTML = 'ğŸ”„ æ­£åœ¨ä¸Šä¼ å¤„ç†...';

    try {
        const response = await fetch('/upload_multimodal', {
            method: 'POST',
            body: formData
        });

        const result = await response.json();

        if (result.success) {
            statusDiv.innerHTML = `âœ… ${result.message}
                <br>ğŸ“„ ç±»å‹: ${result.content_type}, å†…å®¹é•¿åº¦: ${result.content_length}`;
            fileInput.value = ''; // æ¸…ç©ºæ–‡ä»¶é€‰æ‹©
        } else {
            statusDiv.innerHTML = `âŒ ${result.message}`;
        }
    } catch (error) {
        statusDiv.innerHTML = `âŒ ä¸Šä¼ å¤±è´¥: ${error}`;
    }
}
</script>
```

### ç¬¬ä¸‰æ­¥ï¼šæ¸è¿›å¼è¿ç§»ç­–ç•¥

#### 3.1 å…¼å®¹æ€§æµ‹è¯•

```python
# åˆ›å»ºæµ‹è¯•è„šæœ¬ test_multimodal_integration.py

import sys
import os
sys.path.append('.')

from rag_system import AdvancedRAGSystem
from multimodal_processor import MultiModalProcessor
import logging

def test_backward_compatibility():
    """æµ‹è¯•å‘åå…¼å®¹æ€§"""
    print("ğŸ§ª æµ‹è¯•å‘åå…¼å®¹æ€§...")

    # åˆ›å»ºRAGç³»ç»Ÿ
    rag = AdvancedRAGSystem()

    # æµ‹è¯•åŸæœ‰åŠŸèƒ½
    result = rag.build_knowledge_base("test_data", include_images=True)
    print(f"åŸæœ‰åŠŸèƒ½æµ‹è¯•: {result['success']}")

    # æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½
    if result['success']:
        query_result = rag.query("Pythonç¼–ç¨‹åŸºç¡€")
        print(f"æŸ¥è¯¢åŠŸèƒ½æµ‹è¯•: {query_result['success']}")

def test_multimodal_features():
    """æµ‹è¯•å¤šæ¨¡æ€åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•å¤šæ¨¡æ€åŠŸèƒ½...")

    processor = MultiModalProcessor()

    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    test_files = []

    # æµ‹è¯•CSVæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    import pandas as pd
    test_csv = "test_table.csv"
    df = pd.DataFrame({
        'name': ['å¼ ä¸‰', 'æå››', 'ç‹äº”'],
        'age': [25, 30, 35],
        'score': [95, 87, 92]
    })
    df.to_csv(test_csv, index=False)
    test_files.append(test_csv)

    # å¤„ç†æµ‹è¯•æ–‡ä»¶
    for file_path in test_files:
        doc = processor.process_file(file_path)
        print(f"æ–‡ä»¶ {file_path}: ç±»å‹={doc.content_type}, å†…å®¹é•¿åº¦={len(doc.content)}")

        # æ¸…ç†
        if os.path.exists(file_path):
            os.remove(file_path)

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)

    test_backward_compatibility()
    test_multimodal_features()

    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
```

#### 3.2 æ•°æ®è¿ç§»è„šæœ¬

```python
# åˆ›å»ºæ•°æ®è¿ç§»è„šæœ¬ migrate_to_multimodal.py

import pickle
import os
from typing import List
from data_models import Document
from multimodal_processor import EnhancedDocument

def migrate_existing_knowledge_base():
    """è¿ç§»ç°æœ‰çš„knowledge_base.pkl"""

    backup_path = "knowledge_base_backup.pkl"
    original_path = "knowledge_base.pkl"

    if not os.path.exists(original_path):
        print("âŒ æœªæ‰¾åˆ°ç°æœ‰çŸ¥è¯†åº“æ–‡ä»¶")
        return

    try:
        # å¤‡ä»½åŸæ–‡ä»¶
        import shutil
        shutil.copy2(original_path, backup_path)
        print(f"âœ… å·²å¤‡ä»½åŸæ–‡ä»¶åˆ° {backup_path}")

        # åŠ è½½åŸæ•°æ®
        with open(original_path, 'rb') as f:
            old_data = pickle.load(f)

        print(f"ğŸ“Š åŸçŸ¥è¯†åº“åŒ…å« {len(old_data.get('documents', {}))} ä¸ªæ–‡æ¡£")

        # è½¬æ¢ä¸ºæ–°æ ¼å¼ (å®é™…ä¸Šåªæ˜¯æ·»åŠ äº†å…¼å®¹æ€§ï¼Œæ•°æ®ç»“æ„ä¿æŒä¸å˜)
        # æ–°ç‰ˆæœ¬å¯ä»¥ç›´æ¥è¯»å–æ—§æ ¼å¼

        print("âœ… è¿ç§»å®Œæˆï¼Œå‘å‰å…¼å®¹å·²ç¡®ä¿")

    except Exception as e:
        print(f"âŒ è¿ç§»å¤±è´¥: {e}")
        if os.path.exists(backup_path):
            shutil.copy2(backup_path, original_path)
            print("âœ… å·²å›æ»šåˆ°åŸç‰ˆæœ¬")

if __name__ == "__main__":
    migrate_existing_knowledge_base()
```

### ç¬¬å››æ­¥ï¼šéªŒè¯å’Œä¼˜åŒ–

#### 4.1 æ€§èƒ½æµ‹è¯•

```python
# åˆ›å»ºæ€§èƒ½æµ‹è¯•è„šæœ¬ performance_test.py

import time
from multimodal_processor import MultiModalProcessor

def benchmark_processing():
    """æ€§èƒ½åŸºå‡†æµ‹è¯•"""

    processor = MultiModalProcessor()

    # æµ‹è¯•ä¸åŒç±»å‹æ–‡ä»¶çš„å¤„ç†æ—¶é—´
    test_cases = [
        ("test_data/Pythonç¼–ç¨‹åŸºç¡€.txt", "æ–‡æœ¬æ–‡ä»¶"),
        # æ·»åŠ å…¶ä»–æµ‹è¯•æ–‡ä»¶
    ]

    for file_path, file_type in test_cases:
        if os.path.exists(file_path):
            start_time = time.time()
            doc = processor.process_file(file_path)
            end_time = time.time()

            print(f"{file_type} ({os.path.basename(file_path)}): "
                  f"å¤„ç†æ—¶é—´ {end_time - start_time:.2f}ç§’, "
                  f"å†…å®¹é•¿åº¦ {len(doc.content)} å­—ç¬¦")

if __name__ == "__main__":
    benchmark_processing()
```

### ç¬¬äº”æ­¥ï¼šéƒ¨ç½²å’Œç›‘æ§

#### 5.1 æ–°å¢é…ç½® (config.py)

```python
# åœ¨ç°æœ‰é…ç½®æ–‡ä»¶ä¸­æ·»åŠ å¤šåª’ä½“å¤„ç†é…ç½®

class Config:
    # ç°æœ‰é…ç½®ä¿æŒä¸å˜...

    # æ–°å¢å¤šåª’ä½“é…ç½®
    MULTIMODAL_ENABLED = True
    SUPPORTED_TABLE_FORMATS = ['.csv', '.xlsx', '.xls']
    SUPPORTED_IMAGE_FORMATS = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']
    MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB

    # å›¾è¡¨å¤„ç†é…ç½®
    CHART_DETECTION_ENABLED = True
    CHART_CONFIDENCE_THRESHOLD = 0.5

    # å­˜å‚¨é…ç½®
    MULTIMODAL_STORAGE_PATH = "multimodal_knowledge_base.pkl"
    BACKUP_ENABLED = True
    MAX_BACKUPS = 5
```

## ğŸš€ å¿«é€Ÿå¯åŠ¨æ£€æŸ¥æ¸…å•

### âœ… å‡†å¤‡å·¥ä½œ
- [ ] å®‰è£…æ–°å¢ä¾èµ–: `pip install pandas openpyxl`
- [ ] å¤‡ä»½ç°æœ‰ knowledge_base.pkl æ–‡ä»¶
- [ ] å¤åˆ¶ multimodal_processor.py åˆ°é¡¹ç›®ç›®å½•

### âœ… ä»£ç é›†æˆ
- [ ] æ›´æ–° data_models.py (æ·»åŠ æ–°æ•°æ®ç»“æ„)
- [ ] ä¿®æ”¹ rag_system.py (é›†æˆå¤šæ¨¡æ€å¤„ç†å™¨)
- [ ] æ‰©å±• web_app.py (æ·»åŠ æ–°APIç«¯ç‚¹)
- [ ] æ›´æ–° templates/index.html (æ·»åŠ UIæ”¯æŒ)

### âœ… æµ‹è¯•éªŒè¯
- [ ] è¿è¡Œå…¼å®¹æ€§æµ‹è¯•
- [ ] æµ‹è¯•è¡¨æ ¼æ–‡ä»¶å¤„ç†
- [ ] æµ‹è¯•å›¾ç‰‡å›¾è¡¨è¯†åˆ«
- [ ] éªŒè¯Webç•Œé¢åŠŸèƒ½

### âœ… éƒ¨ç½²ä¸Šçº¿
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•
- [ ] é”™è¯¯å¤„ç†éªŒè¯
- [ ] ç”¨æˆ·ç•Œé¢ä¼˜åŒ–
- [ ] æ–‡æ¡£æ›´æ–°

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**Q1: å¯¼å…¥æ¨¡å—å¤±è´¥**
```bash
# ç¡®ä¿å®‰è£…äº†æ‰€æœ‰ä¾èµ–
pip install -r requirements.txt
pip install pandas openpyxl
```

**Q2: å¤„ç†å¤§æ–‡ä»¶æ—¶å†…å­˜ä¸è¶³**
```python
# åœ¨ config.py ä¸­è®¾ç½®æ–‡ä»¶å¤§å°é™åˆ¶
MAX_FILE_SIZE = 5 * 1024 * 1024  # 5MB
```

**Q3: å›¾è¡¨è¯†åˆ«å‡†ç¡®åº¦ä½**
```python
# è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼
CHART_CONFIDENCE_THRESHOLD = 0.3  # é™ä½é˜ˆå€¼
```

**Q4: å‘åå…¼å®¹æ€§é—®é¢˜**
```python
# ç¡®ä¿ä½¿ç”¨ to_legacy_document() æ–¹æ³•
legacy_doc = enhanced_doc.to_legacy_document()
vector_store.add_document(legacy_doc)
```

## ğŸ“ˆ åç»­ä¼˜åŒ–æ–¹å‘

1. **é›†æˆæ›´å…ˆè¿›çš„å¤šæ¨¡æ€æ¨¡å‹** (CLIP, BLIP-2)
2. **å‘é‡æ•°æ®åº“å‡çº§** (Chroma, Pinecone)
3. **åˆ†å¸ƒå¼å¤„ç†æ”¯æŒ** (Celery, Redis)
4. **å®æ—¶æ–‡ä»¶ç›‘æ§** (æ–‡ä»¶ç³»ç»Ÿäº‹ä»¶ç›‘å¬)
5. **æ™ºèƒ½é‡æ’åºç®—æ³•** (å­¦ä¹ ç”¨æˆ·åå¥½)

é€šè¿‡è¿™ä¸ªæ¸è¿›å¼çš„é›†æˆæ–¹æ¡ˆï¼Œæ‚¨å¯ä»¥åœ¨ä¿æŒç°æœ‰åŠŸèƒ½ç¨³å®šçš„å‰æä¸‹ï¼Œé€æ­¥æ‰©å±•å¤šåª’ä½“å¤„ç†èƒ½åŠ›ã€‚